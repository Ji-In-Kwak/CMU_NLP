{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZGnhK_xzWSWl"
   },
   "source": [
    "# 11411/611 -NLP (S22)\n",
    "# Asssignment 3: Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rADZzHRUWqW4"
   },
   "source": [
    "Classifiers are helpful in distinguish texts from different categories. They are vey useful in numerous use cases.\n",
    "\n",
    "In this assignment you will build a Naive Bayes Classifier that will distinguish 6 different languages namely Hausa, Indonesisan, Manobo, Tagalog, Swahili and Nahuatl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HSkIuUb2JvaQ"
   },
   "source": [
    "You are required to program a Naive Bayes Classifier in this HW.\n",
    "\n",
    "Submission Guidelines\n",
    "Deadline: \n",
    "\n",
    "Programming:\n",
    "\n",
    "This notebook contains helpful test cases and additional information about the programming part of the HW. However, you are only required to submit naivebayes.py on Gradescope.\n",
    "We recommended that you first code in the notebook and then copy the corresponding methods/classes to naivebayes.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r3WNycKGGDA9",
    "outputId": "7c3b3be7-225c-4164-b430-15d3450738e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "QHSGpROOYr3Z"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "from operator import itemgetter\n",
    "from math import log\n",
    "from typing import DefaultDict\n",
    "import sys\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138
    },
    "id": "DDg_1WnOawF8",
    "outputId": "221bc693-fe4c-4b10-8ba2-e9bf4ee1e62a"
   },
   "outputs": [],
   "source": [
    "# Define A NaiveBayes class which is used to distinguish between languages using a character bigram model.\n",
    "\n",
    "# Do create necessary variables wherever required.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class NaiveBayes():\n",
    "    def extract_ngrams(self,x: str, n=2) -> \"list[str]\":\n",
    "        ###TODO###\n",
    "        #extract character ngrams\n",
    "        ngrams = []\n",
    "        split_x = x.split(' ')\n",
    "        for i in range(len(split_x)-n):\n",
    "            ngrams.append(' '.join(split_x[i:i+n]))\n",
    "        return set(ngrams)\n",
    "\n",
    "\n",
    "    def smoothed_log_likelihood(self, w: str, c: str, k: int, count: 'DefaultDict[str, Counter]', vocab: \"set[str]\") -> float:\n",
    "        ###TODO###\n",
    "        #apply smoothing\n",
    "        #prob(w|c) = multiply(prob(f_i|c)) = multiply(prob(f_i, c)/f(c))\n",
    "              \n",
    "#         sum_vocab_all = np.sum([count[v][c] for v in vocab])\n",
    "        prob_c = np.log((count[w][c] + 1) / (self.count_sum[c] + len(vocab)))\n",
    "        return prob_c\n",
    "\n",
    "\n",
    "    def train_nb(self, docs: \"list[tuple[str, str]]\", k: int = 1, n: int = 2) -> \"tuple[dict[str, float], DefaultDict[str, DefaultDict[str, float]], set[str], set[str]]\":\n",
    "        ###TODO###\n",
    "        \"\"\"\n",
    "        Train a Naive-Bayes model\n",
    "\n",
    "        :param docs: The documents, each associated with a clas label (document, label)\n",
    "        :type docs: list[tuple[str, str]]\n",
    "        :param k: The value added to the numerator and denominator to smooth likelihoods\n",
    "        :type k: int\n",
    "        :para n: the order of ngrams.\n",
    "        :type b: int\n",
    "        :return: The log priors, log likelihoods, the classes, and the vocabulary for the model at a tuple\n",
    "        :rtype: tuple[dict[str, float], DefaultDict[str, DefaultDict[str, float]], set[str], set[str]]\n",
    "        \"\"\"\n",
    "        ## Initialize vocab (the vocabulary) and docs_by_class (a dictionary in which\n",
    "        ## class labels are keys and lists of documents are values).\n",
    "\n",
    "        vocab = set()   \n",
    "        classes = set([doc[0] for doc in docs])\n",
    "        docs_by_class = {c: [] for c in classes}        \n",
    "\n",
    "        ## Populate vocab and docs_by_class.\n",
    "\n",
    "        for c, doc in docs:\n",
    "\n",
    "            ## Represent documents as collections of ngrams (default n=2)\n",
    "\n",
    "            ngrams = self.extract_ngrams(doc, n=2)\n",
    "            vocab |= ngrams\n",
    "            docs_by_class[c].append(doc)\n",
    "            classes.add(c)\n",
    "\n",
    "        ## Total number of documents in the collection\n",
    "\n",
    "        num_docs = sum([len(docs_by_class[c]) for c in classes])\n",
    "\n",
    "        ## Number of documents in each class (with each label)\n",
    "\n",
    "        num_docs_in_class = {c: 0 for c in classes}\n",
    "\n",
    "        ## The log priors for each class\n",
    "\n",
    "        log_prior = {c : 0 for c in classes}\n",
    "\n",
    "        ## Counts of times a label c occurs with an ngram w\n",
    "\n",
    "        count = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "        log_likelihood = defaultdict(lambda: defaultdict(int))\n",
    "        \n",
    "        self.count_sum = defaultdict(str)\n",
    "\n",
    "        for c, documents in docs_by_class.items():\n",
    "            # Iterate over the documents of class c, accumulating <ngram, class> counts in counts\n",
    "\n",
    "            for d in documents:\n",
    "                d = self.extract_ngrams(d)\n",
    "                for w in d:\n",
    "#                     print(w)\n",
    "                    count[w][c] += 1\n",
    "\n",
    "            ## Calculate the number of documents with class label c\n",
    "            num_docs_in_class[c] = len(documents)\n",
    "\n",
    "            ## Calculate the log prior as the log of the number of documents in class c over the total number of documents\n",
    "\n",
    "            log_prior[c] = np.log(num_docs_in_class[c] / num_docs)\n",
    "\n",
    "            ## Calculate the log likelihood for each (w|c). Smooth by k=1.\n",
    "            \n",
    "            tmp = 0\n",
    "            for v in vocab:\n",
    "                tmp  += count[v][c]\n",
    "            self.count_sum[c] = tmp\n",
    "\n",
    "            for w in vocab:\n",
    "                log_likelihood[w][c] = self.smoothed_log_likelihood(w, c, k, count, vocab)\n",
    "                \n",
    "        return log_prior, log_likelihood, classes, vocab\n",
    "\n",
    "    def classify(self, testdoc: str, log_prior: \"dict[str, float]\", log_likelihood: \"DefaultDict[str, DefaultDict[str, float]]\", classes: \"set[str]\", vocab: \"set[str]\", k: int=1, n: int=2) -> str:\n",
    "        ###TODO###\n",
    "        \"\"\"Given a trained NB model (log_prior, log_likelihood, classes, and vocab), returns the most likely label for the input document.\n",
    "\n",
    "        :param textdoc str: The test document.\n",
    "        :param log_prior dict[str, float]: The log priors of each category. Categories are keys and log priors are values.\n",
    "        :param log_likelihood DefaultDict[str, DefaultDict[str, float]]: The log likelihoods for each combination of word/ngram and class.\n",
    "        :param classes set[str]: The set of class labels (as strings).\n",
    "        :param vocab set[str]: The set of words/negrams in the vocabulary.\n",
    "        :param k int: the value added in smoothing.\n",
    "        \"param n int: the order of ngrams.\n",
    "        :return: The best label for `testdoc` in light of the model.\n",
    "        :rtype: str\n",
    "        \"\"\"\n",
    "        ## Extract a set of ngrams from `testdoc`\n",
    "\n",
    "        doc = self.extract_ngrams(testdoc, n=2)\n",
    "\n",
    "        ## Initialize the sums for each class. These will be the \"scores\" based on which class will be assigned.\n",
    "\n",
    "        class_sum = {c: 0 for c in classes}\n",
    "        \n",
    "#         self.sum_ll = defaultdict(str)\n",
    "\n",
    "        ## Iterate over the classes, computing `class_sum` for each\n",
    "        for c in classes:\n",
    "            ## Initialize `class_sum` with the log prior for the class\n",
    "\n",
    "            class_sum[c] = log_prior[c]\n",
    "\n",
    "            ## Then add the likelihood for each in-vocabulary ngram in the document            \n",
    "            for i, w in enumerate(doc):\n",
    "                if w in vocab:\n",
    "                    try:\n",
    "                        class_sum[c] = class_sum[c] + log_likelihood[w][c] ## Todo \n",
    "                    except ValueError:\n",
    "#                         count =  ## Todo\n",
    "                        count[w] = {c: 0 for c in classes}\n",
    "                        log_likelihood[w][c] = self.smoothed_log_likelihood(w, c, k, count, vocab)\n",
    "                        class_sum[c] = class_sum[c] + log_likelihood[w][c]\n",
    "    \n",
    "    \n",
    "        return max(class_sum.items(), key=itemgetter(1))[0]\n",
    "    \n",
    "    def precision(self,tp: \"dict[str, int]\", fp: \"dict[str, int]\") -> float:\n",
    "        return tp / (tp + fp)\n",
    "\n",
    "    def recall(self,tp: \"dict[str, int]\", fn: \"dict[str, int]\") -> float:\n",
    "        return tp / (tp + fn)\n",
    "\n",
    "    def micro_precision(self, tp: \"dict[str, int]\", fp: \"dict[str, int]\") -> float:\n",
    "        tp_sum = sum(tp.values())\n",
    "        fp_sum = sum(fp.values())\n",
    "        return tp_sum / (tp_sum + fp_sum)\n",
    "\n",
    "    def micro_recall(self, tp: \"dict[str, int]\", fn: \"dict[str, int]\") -> float:\n",
    "        tp_sum = sum(tp.values())\n",
    "        fn_sum = sum(fn.values())\n",
    "        return tp_sum / (tp_sum + fn_sum)\n",
    "\n",
    "    def micro_f1(self, tp: \"dict[str, int]\", fp: \"dict[str, int]\", fn: \"dict[str, int]\") -> float:\n",
    "        mp = self.micro_precision(tp, fp)\n",
    "        mr = self.micro_recall(tp, fn)\n",
    "        return 2 * (mp * mr) / (mp + mr)\n",
    "\n",
    "    def macro_precision(self, tp: \"dict[str, int]\", fp: \"dict[str, int]\") -> float:\n",
    "        n = len(tp)\n",
    "        return (1 / n) * sum([self.precision(tp[c], fp[c]) for c in tp.keys()])\n",
    "\n",
    "    def macro_recall(self, tp: \"dict[str, int]\", fn: \"dict[str, int]\") -> float:\n",
    "        n = len(tp)\n",
    "        return (1 / n) * sum([self.recall(tp[c], fn[c]) for c in tp.keys()])\n",
    "\n",
    "    def macro_f1(self, tp: \"dict[str, int]\", fp: \"dict[str, int]\", fn: \"dict[str, int]\") -> float:\n",
    "        n = len(tp)\n",
    "        return 2 * (self.macro_precision(tp, fp) * self.macro_recall(tp, fn)) / (self.macro_precision(tp, fp) + self.macro_recall(tp, fn))\n",
    "\n",
    "    def evaluate(self, train: \"list[tuple[str, str]]\", eval: \"list[tuple[str, str]]\", n: int=2):\n",
    "        log_prior, log_likelihood, classes, vocab = self.train_nb(train, n = n)\n",
    "        print('training finished')\n",
    "        # Initialize dictionaries for true positives, false positives, and false negatives\n",
    "        tp, fp, fn = defaultdict(int), defaultdict(int), defaultdict(int)\n",
    "        confusion = defaultdict(lambda: defaultdict(int))\n",
    "        for c_ref, doc in eval:\n",
    "            c_hyp = self.classify(doc, log_prior, log_likelihood, classes, vocab, n = n)\n",
    "            confusion[c_ref][c_hyp] += 1\n",
    "            if c_ref == c_hyp:\n",
    "                tp[c_ref] += 1\n",
    "            else:\n",
    "                fn[c_ref] += 1\n",
    "                fp[c_hyp] += 1\n",
    "\n",
    "        return self.macro_precision(tp, fp), self.macro_recall(tp, fn), self.macro_f1(tp, fp, fn), self.micro_precision(tp, fp), self.micro_recall(tp, fn), self.micro_f1(tp, fp, fn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "N-JR6By4Xh8D"
   },
   "outputs": [],
   "source": [
    "with open('train.tsv') as f:\n",
    "    train = [tuple(l.split('\\t')) for l in f]\n",
    "    \n",
    "with open('dev.tsv') as f:\n",
    "    dev = [tuple(l.split('\\t')) for l in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "id": "DveTAgEAFElj",
    "outputId": "b754c1a7-2239-4327-e4b8-5e239aad5483",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp = NaiveBayes()\n",
    "log_prior, log_likelihood, classes, vocab = tmp.train_nb(train, n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(547171,\n",
       " ['Kaya ako',\n",
       "  'ng Bet',\n",
       "  '\"To haka',\n",
       "  'impirnu, agad',\n",
       "  'kuwaweka kwenye',\n",
       "  'binasag ako',\n",
       "  'lama. (Berarti',\n",
       "  'oajsik ora',\n",
       "  'Ilipokuwa wakati',\n",
       "  'tao, ihinarap'])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab), list(vocab)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 547171)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(classes)), len(list(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'tagalog': -13.812375649268787,\n",
       "             'manobo': -13.433410840613695,\n",
       "             'swahili': -12.980951875253222,\n",
       "             'indonesian': -13.444585997330483,\n",
       "             'hausa': -13.36912813829333,\n",
       "             'nahuatl': -13.366425795532617})"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_likelihood['nyumbani akiwa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = NaiveBayes()\n",
    "c_hyp = tmp.classify(dev[200][1], log_prior, log_likelihood, classes, vocab, n = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tagalog',\n",
       " ('tagalog',\n",
       "  'Nang malaman ni Mordecai ang lahat ng ginawa, pinunit niya ang kanyang mga damit at isinuot ang telang magaspang at mga abo. Lumabas siya sa gitna ng siyudad, at umiyak ng isang malakas at mapait na iyak.\\n'))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_hyp, dev[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "id": "rSz9MXmQXik9",
    "outputId": "80621030-c1d0-44df-a4ce-5ddbca95aead"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training finished\n"
     ]
    }
   ],
   "source": [
    "tmp=NaiveBayes()\n",
    "map, mar, maf, mp, mr, mf=tmp.evaluate(train, dev, n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "k3cNih5xpbiH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9961389862205623 0.9926009701763525 0.9943668310907904 0.992326139088729 0.992326139088729 0.992326139088729\n"
     ]
    }
   ],
   "source": [
    "print(map, mar, maf, mp, mr, mf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
